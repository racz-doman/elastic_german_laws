{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from spacy.lang.de import German\n",
    "from tqdm import tqdm\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cleared_data.txt\", \"r\", encoding=\"utf-8\")\n",
    "cleared_data_law = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cleared_data_labels.txt\", \"r\", encoding=\"utf-8\")\n",
    "cleared_data_labels = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_data = []\n",
    "for var in cleared_data_law:\n",
    "    temp = []\n",
    "    for j in list(var.split(\" \")):\n",
    "        temp.append(j)\n",
    "    cleared_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleared_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = Word2Vec(cleared_data,workers=5,iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 'Nummer'\n",
    "modell.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(lst):\n",
    "    suma=0\n",
    "    for word in lst:\n",
    "        suma = suma + modell[word]\n",
    "    return suma/len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_data_vectors = []\n",
    "for sentence in tqdm(cleared_data):\n",
    "    fin_cleared_data.append(avg(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(2,10)\n",
    "for k in K:\n",
    "    print(k)\n",
    "    km = KMeans(n_clusters=k, max_iter=200, n_init=1)\n",
    "    km = km.fit(cleared_data_vectors)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=1)\n",
    "model.fit(X)\n",
    "labels=model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 3\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=1)\n",
    "model.fit(X)\n",
    "labels=model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = modell.wv.vocab.keys()\n",
    "feature_names = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = feature_names\n",
    "for i in range(true_k):\n",
    "    print (\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print (' %s' % terms[ind]),\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result={'cluster':labels,'law':cleared_data_law}\n",
    "result=pd.DataFrame(result)\n",
    "for k in range(0,true_k):\n",
    "    s=result[result.cluster==k]\n",
    "    text=s['law'].str.cat(sep=' ')\n",
    "    text=text.lower()\n",
    "    text=' '.join([word for word in text.split()])\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "    print('Cluster: {}'.format(k))\n",
    "    print('Titles')\n",
    "    titles=law_cl[law_cl.cluster==k]['category']         \n",
    "    print(titles.to_string(index=False))\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "def find_clusters(X, n_clusters, rseed=2):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    \n",
    "    while True:\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = pairwise_distances_argmin(X, centers)\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0)\n",
    "                                for i in range(n_clusters)])\n",
    "        \n",
    "        # 2c. Check for convergence\n",
    "        if np.all(centers == new_centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers, labels\n",
    "\n",
    "centers, labelss = find_clusters(X, 4)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labelss,\n",
    "            s=50, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "# reduce the features to 2D\n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "reduced_features = pca.fit_transform(fin_cleared_data)\n",
    "\n",
    "# reduce the cluster centers to 2D\n",
    "reduced_cluster_centers = pca.transform(model.cluster_centers_)\n",
    "plt.scatter(reduced_features[:,0], reduced_features[:,1], c=model.predict(fin_cleared_data))\n",
    "plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.text import UMAPVisualizer\n",
    "umap = UMAPVisualizer(labels=[\"category\"], metric='cosine')\n",
    "umap.fit(modell.wv.vectors)\n",
    "umap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=labels, s=0.1, cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=20,\n",
    ").fit_transform(modell.wv.vectors)\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1],\n",
    "            c=mnist.target, s=0.1, cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "# reduce the features to 2D\n",
    "umap = umap.UMAP(n_components=2,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = umap.fit_transform(modell.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the cluster centers to 2D\n",
    "reduced_cluster_centerss = umap.transform(model.cluster_centers_)\n",
    "#plt.scatter(standard_embedding[:,0], standard_embedding[:,1], c=model.predict(modell.wv.vectors))\n",
    "plt.scatter(reduced_cluster_centerss[:, 0], reduced_cluster_centerss[:,1], marker='x', s=150, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
